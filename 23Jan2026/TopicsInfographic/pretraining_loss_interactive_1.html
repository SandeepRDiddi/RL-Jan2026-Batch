
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pretraining Loss: Toy Example - Interactive Guide</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
            line-height: 1.6;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }

        header {
            text-align: center;
            margin-bottom: 40px;
        }

        header h1 {
            color: #667eea;
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        header p {
            color: #666;
            font-size: 1.1em;
        }

        .formula {
            background: #f3e5f5;
            border-left: 5px solid #667eea;
            padding: 20px;
            border-radius: 8px;
            margin: 30px 0;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
            font-size: 1.1em;
            color: #333;
        }

        .section {
            margin: 40px 0;
        }

        .section-title {
            font-size: 1.8em;
            color: #667eea;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #f0f0f0;
        }

        .step {
            background: #f9f9f9;
            border-left: 4px solid #667eea;
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
        }

        .step-number {
            display: inline-block;
            width: 40px;
            height: 40px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 50%;
            text-align: center;
            line-height: 40px;
            font-weight: bold;
            margin-right: 10px;
        }

        .step-title {
            font-size: 1.3em;
            font-weight: bold;
            color: #333;
            margin: 10px 0;
        }

        .code-block {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 8px;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            margin: 15px 0;
            font-size: 0.95em;
            line-height: 1.4;
        }

        .example-box {
            background: linear-gradient(135deg, #e0f7f6 0%, #b3f0eb 100%);
            border: 2px solid #4ECDC4;
            padding: 20px;
            border-radius: 8px;
            margin: 15px 0;
        }

        .example-box strong {
            color: #00897b;
        }

        .good {
            background: linear-gradient(135deg, #e8f5e9 0%, #c8f5e6 100%);
            border-left: 4px solid #4caf50;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
        }

        .good::before {
            content: "‚úì ";
            color: #2e7d32;
            font-weight: bold;
            font-size: 1.2em;
        }

        .bad {
            background: linear-gradient(135deg, #ffebee 0%, #ffcdd2 100%);
            border-left: 4px solid #f44336;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
        }

        .bad::before {
            content: "‚úó ";
            color: #c62828;
            font-weight: bold;
            font-size: 1.2em;
        }

        .vocab-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        .vocab-table th {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 12px;
            text-align: left;
            font-weight: bold;
        }

        .vocab-table td {
            padding: 12px;
            border-bottom: 1px solid #f0f0f0;
        }

        .vocab-table tr:nth-child(even) {
            background: #f9f9f9;
        }

        .vocab-table tr:hover {
            background: #f0f4ff;
        }

        .calculation {
            background: #fff8e1;
            border: 2px solid #fbc02d;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
        }

        .calculation-step {
            margin: 10px 0;
            padding: 10px;
            background: white;
            border-radius: 5px;
        }

        .key-insight {
            background: linear-gradient(135deg, #fff9c4 0%, #ffecb3 100%);
            border: 3px solid #f57f17;
            padding: 20px;
            border-radius: 8px;
            margin: 30px 0;
            font-size: 1.1em;
            font-weight: bold;
            text-align: center;
        }

        .math-explain {
            background: #f5f5f5;
            border: 1px solid #ddd;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }

        .math-explain dt {
            font-weight: bold;
            color: #667eea;
            margin-top: 15px;
            font-family: 'Courier New', monospace;
        }

        .math-explain dd {
            margin-left: 20px;
            color: #555;
            margin-bottom: 10px;
        }

        .comparison {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }

        .comparison-item {
            padding: 20px;
            border-radius: 8px;
            border: 2px solid;
        }

        .comparison-item h4 {
            margin-bottom: 10px;
            font-size: 1.1em;
        }

        .comparison-good {
            background: #e8f5e9;
            border-color: #4caf50;
        }

        .comparison-good h4 {
            color: #2e7d32;
        }

        .comparison-bad {
            background: #ffebee;
            border-color: #f44336;
        }

        .comparison-bad h4 {
            color: #c62828;
        }

        .flow-diagram {
            display: flex;
            align-items: center;
            justify-content: space-around;
            flex-wrap: wrap;
            gap: 10px;
            margin: 30px 0;
        }

        .flow-box {
            background: white;
            border: 2px solid #667eea;
            padding: 15px;
            border-radius: 8px;
            text-align: center;
            min-width: 120px;
            flex: 1;
            min-height: 80px;
            display: flex;
            flex-direction: column;
            justify-content: center;
        }

        .flow-arrow {
            font-size: 2em;
            color: #667eea;
            font-weight: bold;
        }

        footer {
            margin-top: 50px;
            padding-top: 20px;
            border-top: 2px solid #f0f0f0;
            text-align: center;
            color: #999;
        }

        @media (max-width: 768px) {
            .comparison {
                grid-template-columns: 1fr;
            }

            .container {
                padding: 20px;
            }

            header h1 {
                font-size: 1.8em;
            }

            .section-title {
                font-size: 1.4em;
            }
        }

        .highlight {
            background: #fff59d;
            padding: 2px 6px;
            border-radius: 3px;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üß† Pretraining Loss: Complete Toy Example</h1>
            <p>Understanding the mathematical formulation with step-by-step calculations</p>
        </header>

        <!-- FORMULA SECTION -->
        <div class="section">
            <div class="section-title">Mathematical Formulation</div>
            
            <div class="formula">
Loss_pretrain = -E_{(w_1,...,w_n) ~ D}[Œ£_{t=1}^{n-1} log P_Œ∏(w_t | w_1, ..., w_{t-1})]
            </div>

            <div class="math-explain">
                <dl>
                    <dt>Loss_pretrain</dt>
                    <dd>The loss function we're trying to minimize by training</dd>

                    <dt>E_{(w_1,...,w_n) ~ D}[...]</dt>
                    <dd>Expected value: average over all sequences in training data D</dd>

                    <dt>Œ£_{t=1}^{n-1}</dt>
                    <dd>Sum from position 1 to n-1 (can't predict past the last token)</dd>

                    <dt>log P_Œ∏(w_t | w_1, ..., w_{t-1})</dt>
                    <dd>Natural logarithm of the probability of predicting token w_t given all previous tokens</dd>

                    <dt>-[...]</dt>
                    <dd>Negative sign: minimize loss = maximize log probability = maximize likelihood</dd>

                    <dt>Œ∏</dt>
                    <dd>Model parameters (weights) that we're training</dd>
                </dl>
            </div>

            <div class="key-insight">
                üéØ KEY INSIGHT: We're training the model to assign HIGH probability to correct tokens!
            </div>
        </div>

        <!-- VOCABULARY SECTION -->
        <div class="section">
            <div class="section-title">Step 1: Create Toy Vocabulary</div>
            
            <div class="step">
                <span class="step-number">1</span>
                <div class="step-title">Pharmaceutical Domain Vocabulary</div>
                <p>We create a small vocabulary of 12 tokens:</p>
            </div>

            <table class="vocab-table">
                <thead>
                    <tr>
                        <th>Token ID</th>
                        <th>Token</th>
                        <th>Example Context</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>0</strong></td>
                        <td>&lt;START&gt;</td>
                        <td>Beginning of sequence</td>
                    </tr>
                    <tr>
                        <td><strong>1</strong></td>
                        <td>Patient</td>
                        <td>Medical subject</td>
                    </tr>
                    <tr>
                        <td><strong>2</strong></td>
                        <td>has</td>
                        <td>Verb: "Patient has"</td>
                    </tr>
                    <tr>
                        <td><strong>3</strong></td>
                        <td>fever</td>
                        <td>Symptom: "Patient has fever"</td>
                    </tr>
                    <tr>
                        <td><strong>4</strong></td>
                        <td>and</td>
                        <td>Conjunction: "fever and"</td>
                    </tr>
                    <tr>
                        <td><strong>5</strong></td>
                        <td>cough</td>
                        <td>Symptom: "and cough"</td>
                    </tr>
                    <tr>
                        <td><strong>6</strong></td>
                        <td>fatigue</td>
                        <td>Symptom: "Patient has fatigue"</td>
                    </tr>
                    <tr>
                        <td><strong>7</strong></td>
                        <td>take</td>
                        <td>Action: "take medicine"</td>
                    </tr>
                    <tr>
                        <td><strong>8</strong></td>
                        <td>acetaminophen</td>
                        <td>Drug: "take acetaminophen"</td>
                    </tr>
                    <tr>
                        <td><strong>9</strong></td>
                        <td>rest</td>
                        <td>Action: "rest"</td>
                    </tr>
                    <tr>
                        <td><strong>10</strong></td>
                        <td>.</td>
                        <td>Punctuation: end of phrase</td>
                    </tr>
                    <tr>
                        <td><strong>11</strong></td>
                        <td>&lt;END&gt;</td>
                        <td>End of sequence</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <!-- SEQUENCES SECTION -->
        <div class="section">
            <div class="section-title">Step 2: Training Sequences</div>
            
            <div class="step">
                <span class="step-number">2</span>
                <div class="step-title">Pharmaceutical Text Examples</div>
                <p>We have 3 pharmaceutical sentences to train on:</p>
            </div>

            <div class="example-box">
                <strong>Sequence 1:</strong> "Patient has fever and cough ."<br/>
                <code>&lt;START&gt; ‚Üí Patient ‚Üí has ‚Üí fever ‚Üí and ‚Üí cough ‚Üí . ‚Üí &lt;END&gt;</code><br/>
                <strong>Token IDs:</strong> [0, 1, 2, 3, 4, 5, 10, 11]
            </div>

            <div class="example-box">
                <strong>Sequence 2:</strong> "Patient has fatigue ."<br/>
                <code>&lt;START&gt; ‚Üí Patient ‚Üí has ‚Üí fatigue ‚Üí . ‚Üí &lt;END&gt;</code><br/>
                <strong>Token IDs:</strong> [0, 1, 2, 6, 10, 11]
            </div>

            <div class="example-box">
                <strong>Sequence 3:</strong> "take acetaminophen rest ."<br/>
                <code>&lt;START&gt; ‚Üí take ‚Üí acetaminophen ‚Üí rest ‚Üí . ‚Üí &lt;END&gt;</code><br/>
                <strong>Token IDs:</strong> [0, 7, 8, 9, 10, 11]
            </div>
        </div>

        <!-- NEXT-TOKEN PREDICTION -->
        <div class="section">
            <div class="section-title">Step 3: Next-Token Prediction</div>
            
            <div class="step">
                <span class="step-number">3</span>
                <div class="step-title">The Core Idea</div>
                <p>For each position t, we predict the next token from ALL previous tokens:</p>
            </div>

            <div class="code-block">
Position t=1:
  Context: &lt;START&gt;
  Predict: Patient
  Need: P_Œ∏(Patient | &lt;START&gt;)

Position t=2:
  Context: &lt;START&gt; Patient
  Predict: has
  Need: P_Œ∏(has | &lt;START&gt; Patient)

Position t=3:
  Context: &lt;START&gt; Patient has
  Predict: fever
  Need: P_Œ∏(fever | context)

... and so on for all positions
            </div>

            <div class="key-insight">
                ‚úì We predict each token from the COMPLETE history of all previous tokens!
            </div>
        </div>

        <!-- LOSS CALCULATION -->
        <div class="section">
            <div class="section-title">Step 4: Loss Calculation with Real Numbers</div>
            
            <div class="step">
                <span class="step-number">4</span>
                <div class="step-title">Pharmaceutical Example Calculation</div>
                <p>Let's compute loss for: <strong>"Patient has fever ."</strong></p>
            </div>

            <div class="calculation">
                <div class="calculation-step">
                    <strong>Position 1:</strong><br/>
                    Context: &lt;START&gt; | Target: Patient<br/>
                    P(Patient | &lt;START&gt;) = 0.85<br/>
                    log(0.85) = -0.163<br/>
                    <strong style="color: #2e7d32;">Loss = 0.163 ‚úì GOOD</strong>
                </div>

                <div class="calculation-step">
                    <strong>Position 2:</strong><br/>
                    Context: &lt;START&gt; Patient | Target: has<br/>
                    P(has | context) = 0.92<br/>
                    log(0.92) = -0.083<br/>
                    <strong style="color: #2e7d32;">Loss = 0.083 ‚úì GOOD</strong>
                </div>

                <div class="calculation-step">
                    <strong>Position 3:</strong><br/>
                    Context: &lt;START&gt; Patient has | Target: fever<br/>
                    P(fever | context) = 0.78<br/>
                    log(0.78) = -0.248<br/>
                    <strong style="color: #f57f17;">Loss = 0.248 ‚óã OK</strong>
                </div>

                <div class="calculation-step">
                    <strong>Position 4:</strong><br/>
                    Context: &lt;START&gt; Patient has fever | Target: .<br/>
                    P(. | context) = 0.81<br/>
                    log(0.81) = -0.211<br/>
                    <strong style="color: #2e7d32;">Loss = 0.211 ‚úì GOOD</strong>
                </div>

                <hr style="margin: 15px 0; border: none; border-top: 2px solid #333;">

                <div style="font-size: 1.1em; font-weight: bold; text-align: center; color: #333;">
                    TOTAL LOSS = 0.163 + 0.083 + 0.248 + 0.211 = 0.705<br/>
                    AVERAGE LOSS PER TOKEN = 0.705 / 4 = 0.176
                </div>
            </div>
        </div>

        <!-- PROBABILITY INTERPRETATION -->
        <div class="section">
            <div class="section-title">Step 5: Understanding Probability & Loss</div>

            <div class="comparison">
                <div class="comparison-item comparison-good">
                    <h4>High Probability (Good Prediction)</h4>
                    <p><strong>P(token) = 0.85</strong></p>
                    <p>log(0.85) = -0.163</p>
                    <p><strong style="color: #2e7d32;">Loss = 0.163</strong></p>
                    <p style="font-size: 0.9em; color: #555; margin-top: 10px;">Model confident & correct ‚Üí Small loss</p>
                </div>

                <div class="comparison-item comparison-bad">
                    <h4>Low Probability (Bad Prediction)</h4>
                    <p><strong>P(token) = 0.05</strong></p>
                    <p>log(0.05) = -2.996</p>
                    <p><strong style="color: #c62828;">Loss = 2.996</strong></p>
                    <p style="font-size: 0.9em; color: #555; margin-top: 10px;">Model not confident & wrong ‚Üí Large loss</p>
                </div>
            </div>

            <div class="key-insight">
                üîë The loss is LARGE for wrong predictions and SMALL for correct ones!<br/>
                This guides the optimizer to improve the model.
            </div>
        </div>

        <!-- TRAINING PROGRESSION -->
        <div class="section">
            <div class="section-title">Step 6: What Happens During Training</div>

            <div class="step">
                <span class="step-number">6</span>
                <div class="step-title">Training Progress</div>
            </div>

            <div style="margin: 20px 0;">
                <strong style="display: block; margin-bottom: 15px; font-size: 1.1em;">Before Training (Random Model):</strong>
                <div class="bad">
                    All tokens equally likely: P(any token) = 1/12 ‚âà 0.083<br/>
                    log(0.083) = -2.492<br/>
                    <strong>Average loss per token ‚âà 2.49 (VERY BAD)</strong>
                </div>
            </div>

            <div style="margin: 20px 0;">
                <strong style="display: block; margin-bottom: 15px; font-size: 1.1em;">After 1 Epoch (Learning Starts):</strong>
                <div class="example-box" style="border-color: #ff9800;">
                    Model learns some patterns<br/>
                    P(common tokens) increases, P(rare tokens) decreases<br/>
                    <strong>Average loss per token ‚âà 1.25 (Better!)</strong>
                </div>
            </div>

            <div style="margin: 20px 0;">
                <strong style="display: block; margin-bottom: 15px; font-size: 1.1em;">After 100 Epochs (Well-Trained):</strong>
                <div class="good">
                    Model has learned patterns well<br/>
                    Correct tokens assigned high probability<br/>
                    <strong>Average loss per token ‚âà 0.22 (Excellent!)</strong>
                </div>
            </div>
        </div>

        <!-- WHAT MODEL LEARNS -->
        <div class="section">
            <div class="section-title">Step 7: What Does the Model Actually Learn?</div>

            <div class="step">
                <span class="step-number">7</span>
                <div class="step-title">Statistical Patterns</div>
            </div>

            <div class="example-box">
                <strong>Pattern 1: Medical Contexts</strong><br/>
                "Patient has" ‚Üí {fever, cough, fatigue} with HIGH probability<br/>
                Model learns these are likely symptoms after this phrase.
            </div>

            <div class="example-box">
                <strong>Pattern 2: Treatment Suggestions</strong><br/>
                "Patient has fever ." ‚Üí {take, acetaminophen} with good probability<br/>
                Model learns this is a common treatment pattern.
            </div>

            <div class="example-box">
                <strong>Pattern 3: Common Phrases</strong><br/>
                "take" ‚Üí {acetaminophen, aspirin, rest} with HIGH probability<br/>
                Model learns these commonly follow "take".
            </div>

            <div class="example-box">
                <strong>Pattern 4: Sentence Structure</strong><br/>
                After any phrase ‚Üí "." is LIKELY<br/>
                Model learns punctuation patterns.
            </div>

            <div class="key-insight">
                ‚ö†Ô∏è Model learns PATTERNS ONLY, not SAFETY or ALIGNMENT!<br/>
                If data has bad patterns, model learns them too.<br/>
                This is why we need Stages 2-4 (SFT, RM, PPO).
            </div>
        </div>

        <!-- MATHEMATICAL INSIGHT -->
        <div class="section">
            <div class="section-title">Step 8: Mathematical Deep Dive</div>

            <div class="step">
                <span class="step-number">8</span>
                <div class="step-title">Connection to Maximum Likelihood</div>
            </div>

            <div style="background: #f0f4ff; border: 2px solid #667eea; padding: 20px; border-radius: 8px; margin: 20px 0;">
                <p style="margin-bottom: 15px;">
                    <strong>Minimizing:</strong> -log P(data | model)<br/>
                    <strong>Equivalent to:</strong> Maximizing log P(data | model)<br/>
                    <strong>Which is:</strong> Maximizing P(data | model)<br/>
                    <strong>This is:</strong> MAXIMUM LIKELIHOOD ESTIMATION!
                </p>
                
                <p style="margin-bottom: 15px;">
                    <strong>Information Theory Perspective:</strong><br/>
                    Cross-entropy = Average "surprise" of predicting correct tokens<br/>
                    High surprise (large loss) = wrong predictions<br/>
                    Low surprise (small loss) = correct predictions
                </p>

                <p>
                    <strong>Practical Result:</strong><br/>
                    The model learns the <span class="highlight">empirical probability distribution</span> of the training data!<br/>
                    P_Œ∏(token) ‚âà Frequency(token) in training data
                </p>
            </div>
        </div>

        <!-- KEY INSIGHTS -->
        <div class="section">
            <div class="section-title">Summary: Key Takeaways</div>

            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 20px 0;">
                <div class="good" style="padding: 20px;">
                    <strong>What the Model Learns:</strong><br/>
                    ‚úì Statistical patterns in text<br/>
                    ‚úì Word frequencies and sequences<br/>
                    ‚úì Domain vocabulary<br/>
                    ‚úì Grammar and structure<br/>
                    ‚úì Semantic relationships
                </div>

                <div class="bad" style="padding: 20px;">
                    <strong>What it Does NOT Learn:</strong><br/>
                    ‚úó Safety or truthfulness<br/>
                    ‚úó Right vs wrong<br/>
                    ‚úó Alignment with human values<br/>
                    ‚úó Harmful pattern avoidance<br/>
                    ‚úó Ethical reasoning
                </div>
            </div>

            <div class="key-insight">
                üìå FINAL INSIGHT<br/>
                Pretraining teaches pattern matching, not alignment.<br/>
                This is why we need SFT ‚Üí RM ‚Üí PPO pipeline!
            </div>
        </div>

        <footer>
            <p>üìä Interactive Toy Example | Complete Mathematical Explanation | Pharmaceutical Examples</p>
            <p>Use this to understand why models need multi-stage training for safety and alignment</p>
        </footer>
    </div>
</body>
</html>
